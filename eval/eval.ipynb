{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型评估脚本\n",
    "\n",
    "这个脚本用于评估基于transformers库的模型在古文翻译任务上的性能。\n",
    "\n",
    "- **模型加载**: 加载预训练模型和分词器。\n",
    "- **文本翻译**: 通过模型将文言文翻译为白话文。\n",
    "- **评估过程**: 对模型的翻译结果进行BLEU评分，以评估翻译质量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from typing import List, Dict\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义全局常量\n",
    "# model_name_or_path=模型路径\n",
    "\n",
    "model_name_or_path = '/root/ChatGLM3/chatglm3-6b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c117759ce6d04288b006088ef83aba0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model dtype: torch.float16\n"
     ]
    }
   ],
   "source": [
    "# 加载模型和分词器\n",
    "model = AutoModel.from_pretrained(model_name_or_path, trust_remote_code=True).half().cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=True)\n",
    "model = model.eval()\n",
    "# 打印模型的数据精度\n",
    "print(f\"model dtype: {model.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提示构造\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"任务：将下面的文言文文本翻译成现代白话文。\\n\"\n",
    "        \"注意：请保持翻译的准确性和流畅性，尽量还原原文的意境和风格。\\n\"\n",
    "        \"{terms}\"  # 如有专业术语或特定背景，将在这里显示\n",
    "        \"文言文输入：\\n{input}\\n\"\n",
    "        \"白话文翻译：\\n\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# 功能函数\n",
    "def generate_output_from_text(text_list: List[str]) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    生成文本输出。\n",
    "\n",
    "    :param text_list: 需要翻译的文言文文本列表。\n",
    "    :param terms_list: 对应每个文言文文本的专业术语列表。每个列表包含词典，其中包含术语的源文本、标签和目标文本。\n",
    "    :return: 包含模型翻译输出的字典列表。\n",
    "    \"\"\"\n",
    "    result_list = []\n",
    "\n",
    "    for idx, text in enumerate(text_list):\n",
    "        # 使用PROMPT_DICT构造完整的输入提示\n",
    "        prompt = PROMPT_DICT[\"prompt_input\"].format(input=text, terms=\"\")\n",
    "        # 调用模型进行翻译\n",
    "        result = model.chat(tokenizer, prompt, history=[])[0]\n",
    "        result_list.append({\"text\": result})\n",
    "\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我们要尊重老人，就像尊重别人一样；我们要关心孩子，就像关心自己一样。\n"
     ]
    }
   ],
   "source": [
    "# 使用方法：\n",
    "text_list = [\"老吾老，以及人之老；幼吾幼，以及人之幼\"]\n",
    "results = generate_output_from_text(text_list)\n",
    "print(results[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "青色是从蓝色中提取的，但青色比蓝色更鲜艳；冰是由水凝结而成的，但它比水更寒冷。\n"
     ]
    }
   ],
   "source": [
    "# 使用方法：\n",
    "text_list = [\"青，取之于蓝，而青于蓝；冰，水为之，而寒于水。\"]\n",
    "results = generate_output_from_text(text_list)\n",
    "print(results[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "十三年，我担任武昌知府。当时吴三桂侵犯湖南，军队正围攻岳州，我下令让成龙建造浮桥以方便军队通行，但浮桥刚刚建成，山水爆发，浮桥被毁，因此我失去了官职。\n"
     ]
    }
   ],
   "source": [
    "# 使用方法：\n",
    "text_list = [\"十三年，署武昌知府。吴三桂犯湖南，师方攻岳州，檄成龙造浮桥济师，甫成，山水发，桥圮，坐夺官。\"]\n",
    "results = generate_output_from_text(text_list)\n",
    "print(results[0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进行评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义全局常量\n",
    "# eva_file_path=用于评估的文件路径\n",
    "# output_file_path=评估结果输出路径\n",
    "\n",
    "eva_file_path = r\"/root/xm/HistoryTrans/data/version4/sampled_50_merged_output_20230812_190843.json\"\n",
    "output_file_path = \"./data/eval_results/\"\n",
    "\n",
    "# 检查输出文件夹是否存在，如果不存在则创建\n",
    "if not os.path.exists(output_file_path):\n",
    "    os.makedirs(output_file_path)\n",
    "\n",
    "# 读取评估数据\n",
    "with open(eva_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu(reference, candidate):\n",
    "    reference = [list(reference)]\n",
    "    candidate = list(candidate)\n",
    "    return sentence_bleu(reference, candidate, smoothing_function=SmoothingFunction().method1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始评估，共 50 个样本.\n",
      "评估进度: 1/50, 当前样本BLEU分数: 0.75\n",
      "评估进度: 2/50, 当前样本BLEU分数: 0.19\n",
      "评估进度: 3/50, 当前样本BLEU分数: 0.02\n",
      "评估进度: 4/50, 当前样本BLEU分数: 0.11\n",
      "评估进度: 5/50, 当前样本BLEU分数: 0.05\n",
      "评估进度: 6/50, 当前样本BLEU分数: 0.55\n",
      "评估进度: 7/50, 当前样本BLEU分数: 0.28\n",
      "评估进度: 8/50, 当前样本BLEU分数: 0.19\n",
      "评估进度: 9/50, 当前样本BLEU分数: 0.20\n",
      "评估进度: 10/50, 当前样本BLEU分数: 0.38\n",
      "评估进度: 11/50, 当前样本BLEU分数: 0.16\n",
      "评估进度: 12/50, 当前样本BLEU分数: 0.02\n",
      "评估进度: 13/50, 当前样本BLEU分数: 0.20\n",
      "评估进度: 14/50, 当前样本BLEU分数: 0.19\n",
      "评估进度: 15/50, 当前样本BLEU分数: 0.46\n",
      "评估进度: 16/50, 当前样本BLEU分数: 0.03\n",
      "评估进度: 17/50, 当前样本BLEU分数: 0.01\n",
      "评估进度: 18/50, 当前样本BLEU分数: 0.07\n",
      "评估进度: 19/50, 当前样本BLEU分数: 0.07\n",
      "评估进度: 20/50, 当前样本BLEU分数: 0.06\n",
      "评估进度: 21/50, 当前样本BLEU分数: 0.04\n",
      "评估进度: 22/50, 当前样本BLEU分数: 0.12\n",
      "评估进度: 23/50, 当前样本BLEU分数: 0.66\n",
      "评估进度: 24/50, 当前样本BLEU分数: 0.02\n",
      "评估进度: 25/50, 当前样本BLEU分数: 0.05\n",
      "评估进度: 26/50, 当前样本BLEU分数: 0.09\n",
      "评估进度: 27/50, 当前样本BLEU分数: 0.01\n",
      "评估进度: 28/50, 当前样本BLEU分数: 0.09\n",
      "评估进度: 29/50, 当前样本BLEU分数: 0.05\n",
      "评估进度: 30/50, 当前样本BLEU分数: 0.25\n",
      "评估进度: 31/50, 当前样本BLEU分数: 0.01\n",
      "评估进度: 32/50, 当前样本BLEU分数: 0.02\n",
      "评估进度: 33/50, 当前样本BLEU分数: 0.15\n",
      "评估进度: 34/50, 当前样本BLEU分数: 0.07\n",
      "评估进度: 35/50, 当前样本BLEU分数: 0.09\n",
      "评估进度: 36/50, 当前样本BLEU分数: 0.03\n",
      "评估进度: 37/50, 当前样本BLEU分数: 0.21\n",
      "评估进度: 38/50, 当前样本BLEU分数: 0.18\n",
      "评估进度: 39/50, 当前样本BLEU分数: 0.21\n",
      "评估进度: 40/50, 当前样本BLEU分数: 0.03\n",
      "评估进度: 41/50, 当前样本BLEU分数: 0.21\n",
      "评估进度: 42/50, 当前样本BLEU分数: 0.03\n",
      "评估进度: 43/50, 当前样本BLEU分数: 0.24\n",
      "评估进度: 44/50, 当前样本BLEU分数: 0.38\n",
      "评估进度: 45/50, 当前样本BLEU分数: 0.07\n",
      "评估进度: 46/50, 当前样本BLEU分数: 0.02\n",
      "评估进度: 47/50, 当前样本BLEU分数: 0.02\n",
      "评估进度: 48/50, 当前样本BLEU分数: 0.09\n",
      "评估进度: 49/50, 当前样本BLEU分数: 0.02\n",
      "评估进度: 50/50, 当前样本BLEU分数: 0.07\n"
     ]
    }
   ],
   "source": [
    "# 初始化评估结果\n",
    "evaluation_results = {\n",
    "    \"scores\": {\"average_BLEU\": 0},\n",
    "    \"infos\": {\n",
    "        \"evaluation_time\": time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime()),\n",
    "        \"model_name_or_path\": model_name_or_path,\n",
    "    },\n",
    "    \"samples\": []\n",
    "}\n",
    "\n",
    "# 开始评估\n",
    "total_bleu_score = 0\n",
    "total_samples = len(data)\n",
    "print(f\"开始评估，共 {total_samples} 个样本.\")\n",
    "\n",
    "for i, example in enumerate(data):\n",
    "    inputs = example[\"input\"]\n",
    "    truths = [example[\"output\"]]\n",
    "    results = generate_output_from_text([inputs])\n",
    "    results_str = results[0]['text']\n",
    "    max_bleu_score = max(calculate_bleu(truth, results_str) for truth in truths)\n",
    "    total_bleu_score += max_bleu_score\n",
    "\n",
    "    # 将每个样本的评估结果添加到evaluation_results中\n",
    "    evaluation_results[\"samples\"].append({\n",
    "        \"inputs\": inputs,\n",
    "        \"truth\": truths[0],\n",
    "        \"results\": results_str,\n",
    "        \"BLEU\": max_bleu_score\n",
    "    })\n",
    "\n",
    "    # 打印进度和当前样本的BLEU分数\n",
    "    print(f\"评估进度: {i+1}/{total_samples}, 当前样本BLEU分数: {max_bleu_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "评估完成，平均BLEU分数为: 0.15\n",
      "评估结果已保存到 ./data/eval_results/evaluation_results_20231217163932.json\n"
     ]
    }
   ],
   "source": [
    "# 计算平均BLEU分数并保存评估结果\n",
    "evaluation_results[\"scores\"][\"average_BLEU\"] = total_bleu_score / total_samples\n",
    "result_file = os.path.join(output_file_path, f\"evaluation_results_{time.strftime('%Y%m%d%H%M%S', time.localtime())}.json\")\n",
    "with open(result_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(evaluation_results, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"评估完成，平均BLEU分数为: {evaluation_results['scores']['average_BLEU']:.2f}\")\n",
    "print(f\"评估结果已保存到 {result_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
