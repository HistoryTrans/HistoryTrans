{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "评估模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModel\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "# import os\n",
    "\n",
    "# result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "# output = result.stdout\n",
    "# for line in output.splitlines():\n",
    "#     if '=' in line:\n",
    "#         var, value = line.split('=', 1)\n",
    "#         os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "434d71b25ab44ba6a5bbaa74e7f9b59d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。请查看单元格中的代码，以确定故障的可能原因。有关详细信息，请单击 <a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>。有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "model_name_or_path = 'THUDM/chatglm3-6b'\n",
    "model = AutoModel.from_pretrained(\"THUDM/chatglm3-6b\", trust_remote_code=True).half().cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"THUDM/chatglm3-6b\", trust_remote_code=True)\n",
    "\n",
    "print(f\"加载了模型 model={model_name_or_path}\")\n",
    "print(f\"加载了分词器 tokenizer={model_name_or_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全局常量：样本构造提示\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\"下面是一段文言文文本，请直接将它翻译成白话文。\\n\" \"{terms}\" \"#文言文文本:\\n{input}\\n\\n#白话文文本:\\n\")\n",
    "}\n",
    "\n",
    "\n",
    "def generate_input_prompt(text, terms=None):\n",
    "    terms_prompt = \"\"\n",
    "    if terms:\n",
    "        terms_prompt = \"#需应用术语:\\n\"\n",
    "        for term in terms:\n",
    "            terms_prompt += f\"{term['src']}\\t{term['tag']}\\t{term['tgt']}\\n\"\n",
    "    source = PROMPT_DICT[\"prompt_input\"].format(\n",
    "        input=text, terms=terms_prompt\n",
    "    )\n",
    "    return source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = [\"老吾老，以及人之老；幼吾幼，以及人之幼\"]\n",
    "\n",
    "# 生成模型输入\n",
    "prompts = [generate_input_prompt(text) for text in text_list]\n",
    "for prompt in prompts:\n",
    "    response, history = model.chat(tokenizer, prompt, history=[])\n",
    "    print(response)\n",
    "    # print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "def generate_output_from_text(text_list: List[str], tokenizer) -> List[Dict[str, str]]:\n",
    "    \n",
    "    # 生成模型输入\n",
    "    prompts = [generate_input_prompt(text) for text in text_list]\n",
    "    result_list = []\n",
    "    # 从输出中提取结果\n",
    "    for prompt in prompts:\n",
    "        response, history = model.chat(tokenizer, prompt, history=[])\n",
    "        result_list.append({\"text\": response})\n",
    "\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用方法：\n",
    "text_list = [\"青，取之于蓝，而青于蓝；冰，水为之，而寒于水。\"]\n",
    "results = generate_output_from_text(text_list, tokenizer)\n",
    "print(results[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用方法：\n",
    "text_list = [\"十三年，署武昌知府。吴三桂犯湖南，师方攻岳州，檄成龙造浮桥济师，甫成，山水发，桥圮，坐夺官。\"]\n",
    "results = generate_output_from_text(text_list, tokenizer)\n",
    "print(results[0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import json\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "def create_logger():\n",
    "    # 创建一个logger\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    # 创建一个handler，用于写入日志文件\n",
    "    log_dir = './data/eval_py_logs'\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    log_file = os.path.join(log_dir, 'eval_'+ (datetime.datetime.utcnow() + datetime.timedelta(hours=8)).strftime('%Y%m%d_%H%M%S') + '.log')\n",
    "    file_handler = logging.FileHandler(log_file)\n",
    "    file_handler.setLevel(logging.INFO)\n",
    "\n",
    "    # 创建一个handler，用于输出到控制台\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setLevel(logging.INFO)\n",
    "\n",
    "    # 定义handler的输出格式\n",
    "    # formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    formatter = logging.Formatter('')\n",
    "    file_handler.setFormatter(formatter)\n",
    "    console_handler.setFormatter(formatter)\n",
    "\n",
    "    # 给logger添加handler\n",
    "    logger.addHandler(file_handler)\n",
    "    logger.addHandler(console_handler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "# 使用create_logger函数来创建一个新的logger\n",
    "logger = create_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"当前时间：{}\".format(datetime.datetime.utcnow()))\n",
    "logger.info(\"base_model: {}\".format(eval_args.model_name_or_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算BLEU分数\n",
    "def calculate_bleu(reference, candidate):\n",
    "    reference = [list(reference)]\n",
    "    candidate = list(candidate)\n",
    "    smoothing_function = SmoothingFunction().method1\n",
    "    return sentence_bleu(reference, candidate, smoothing_function=smoothing_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eva_file_path = \"./data/eval_data.json\"\n",
    "output_file_path = \"./data/eval_results/\"\n",
    "import os\n",
    "if not os.path.exists(output_file_path):\n",
    "    os.makedirs(output_file_path)\n",
    "\n",
    "# 加载数据\n",
    "with open(eva_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "print(f\"评估文件：{eva_file_path}加载完成\")\n",
    "print(f\"共加载{len(data)}个样本, 开始评估...\")\n",
    "logger.info(f\"共加载{len(data)}个样本, 开始评估...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得绝对路径\n",
    "local_time = time.localtime()\n",
    "time_str = time.strftime(\"%Y/%m/%d %H:%M:%S\", local_time)\n",
    "\n",
    "print(f\"当前时间：{time_str}\")\n",
    "print(\"开始评估...\")\n",
    "\n",
    "evaluation_results = {\n",
    "    \"scores\": {\"average_BLEU\": 0},\n",
    "    \"infos\":{\n",
    "        \"evaluation_time\": time_str,\n",
    "        \"base_model\": eval_args.model_name_or_path,\n",
    "    },\n",
    "    \"samples\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_bleu_score = 0\n",
    "\n",
    "# 对每个样本进行评估，并记录进度\n",
    "for i, example in enumerate(data):\n",
    "    print(f\"正在评估第{i+1}个样本，共{len(data)}个样本\")\n",
    "    logging.info(f\"正在评估第{i+1}个样本，共{len(data)}个样本\")\n",
    "    inputs = example[\"input\"]\n",
    "    truths = example[\"output\"]  # 注意这里truths是一个列表\n",
    "    text_list = [inputs]\n",
    "    results = generate_output_from_text(text_list, tokenizer)\n",
    "\n",
    "    results_str = results[0]['text']\n",
    "    \n",
    "    logging.info(\"inputs: {}\".format(inputs))\n",
    "    logging.info(\"results: {}\".format(results[0]['text']))\n",
    "\n",
    "    # 对每个truth计算BLEU分数，并选择最高的BLEU分数\n",
    "    max_bleu_score = 0\n",
    "    # 保存最高分数的truth\n",
    "    max_truth = \"\"\n",
    "    for truth in truths:\n",
    "        truth_str = str(truth)\n",
    "        logging.info(\"truth: {}\".format(truth_str))\n",
    "        bleu_score = calculate_bleu(truth_str, results_str)\n",
    "        if bleu_score > max_bleu_score:\n",
    "            max_bleu_score = bleu_score\n",
    "            max_truth = truth_str\n",
    "\n",
    "    total_bleu_score += max_bleu_score\n",
    "\n",
    "    sample = {\n",
    "        \"inputs\": inputs,\n",
    "        \"truth\": max_truth,\n",
    "        \"results\": results_str,\n",
    "        \"BLEU\": max_bleu_score,\n",
    "    }\n",
    "    evaluation_results[\"samples\"].append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算总的BLEU分数\n",
    "evaluation_results[\"scores\"][\"average_BLEU\"] = total_bleu_score / len(data)\n",
    "logging.info(\"评估完成，平均BLEU分数为{}\".format(evaluation_results['scores']['average_BLEU']))\n",
    "print(\"评估完成，平均BLEU分数为{}\".format(evaluation_results['scores']['average_BLEU']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存评估结果\n",
    "time_str = time.strftime(\"%Y%m%d%H%M%S\", local_time)\n",
    "output_file_path = output_file_path + f\"evaluation_results_{time_str}.json\"\n",
    "with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(evaluation_results, f, ensure_ascii=False, indent=4)\n",
    "logging.info(\"评估结果已保存到{}\".format(output_file_path))\n",
    "print(\"评估结果已保存到{}\".format(output_file_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
