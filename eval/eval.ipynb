{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型评估脚本\n",
    "\n",
    "这个脚本用于评估基于transformers库的模型在古文翻译任务上的性能。\n",
    "\n",
    "- **模型加载**: 加载预训练模型和分词器。\n",
    "- **文本翻译**: 通过模型将文言文翻译为白话文。\n",
    "- **评估过程**: 对模型的翻译结果进行BLEU评分，以评估翻译质量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from typing import List, Dict\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义全局常量\n",
    "# model_name_or_path=模型路径\n",
    "\n",
    "model_name_or_path = 'THUDM/chatglm3-6b'\n",
    "model_name_or_path = '/root/.cache/huggingface/hub/models--THUDM--chatglm3-6b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df60523e8461479c92c767d798e48f01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model dtype: torch.float16\n"
     ]
    }
   ],
   "source": [
    "# 加载模型和分词器\n",
    "model = AutoModel.from_pretrained(model_name_or_path, trust_remote_code=True).half().cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=True)\n",
    "model = model.eval()\n",
    "# 打印模型的数据精度\n",
    "print(f\"model dtype: {model.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提示构造\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"下面是一段文言文文本，请直接将它翻译成白话文。\\n\"\n",
    "        \"{terms}\"  # 如有专业术语或特定背景，将在这里显示\n",
    "        \"#文言文文本:\\n{input}\\n\"\n",
    "        \"#白话文文本:\\n\"\n",
    "    )\n",
    "}\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "eos_token_id = [tokenizer.eos_token_id, tokenizer.get_command(\"<|user|>\"),\n",
    "                        tokenizer.get_command(\"<|observation|>\")]\n",
    "max_length= 1024\n",
    "# num_beams=1\n",
    "# do_sample=True\n",
    "top_p=0.8\n",
    "temperature=0.1\n",
    "# gen_kwargs = {\"max_length\": max_length, \"num_beams\": num_beams, \"do_sample\": do_sample, \"top_p\": top_p,\"temperature\": temperature}\n",
    "gen_kwargs = {\"max_length\": max_length, \"top_p\": top_p,\"temperature\": temperature}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output_from_text_batch(text_list: List[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    生成批量文本输出。\n",
    "\n",
    "    :param text_list: 需要翻译的文言文文本列表。\n",
    "    :return: 模型翻译输出的列表。\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    # 使用PROMPT_DICT构造输入提示\n",
    "    batch_prompts = [PROMPT_DICT[\"prompt_input\"].format(input=text, terms=\"\") for text in text_list]\n",
    "    inputs = tokenizer.batch_encode_plus(batch_prompts, return_tensors='pt', padding=True, max_length=512, truncation=True)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}  # 移动输入到正确的设备\n",
    "\n",
    "    # 生成翻译输出\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs['input_ids'],\n",
    "        **gen_kwargs,\n",
    "        eos_token_id=eos_token_id\n",
    "    )\n",
    "\n",
    "    # 处理每个生成的输出\n",
    "    for j, output in enumerate(outputs):\n",
    "        decoded_output = tokenizer.decode(output, skip_special_tokens=True)\n",
    "        translation = decoded_output.replace(batch_prompts[j], \"\").strip()\n",
    "        # 替换开头的特殊标记（如果存在）\n",
    "        results.append(translation.replace(\"[gMASK]sop \", \"\"))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results=['要尊重老人，也要尊重别人家的老人；要关心孩子，也要关心别人家的孩子。', '古代的学者一定有老师。老师，是为了传承道理、教授学问、解答疑惑。']\n"
     ]
    }
   ],
   "source": [
    "# 使用方法：\n",
    "text_list = [\"老吾老，以及人之老；幼吾幼，以及人之幼\", \"古之学者必有师。师者， 所以传道受业解惑也。\"]\n",
    "results = generate_output_from_text_batch(text_list)\n",
    "print(f\"results={results}\")\n",
    "# print(results[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results=['青色是从蓝色中提取的，但青色比蓝色更鲜艳；冰是由水制成的，但冰的寒冷程度超过了水。']\n"
     ]
    }
   ],
   "source": [
    "# 使用方法：\n",
    "text_list = [\"青，取之于蓝，而青于蓝；冰，水为之，而寒于水。\"]\n",
    "results = generate_output_from_text_batch(text_list)\n",
    "print(f\"results={results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results=['十三年，我担任武昌知府。那时吴三桂侵犯湖南，我们的军队正攻打岳州。我发布文书请求成龙制造浮桥来帮助军队渡河，浮桥刚刚建成，山水爆发，桥毁了，因此我失去了官职。']\n"
     ]
    }
   ],
   "source": [
    "# 使用方法：\n",
    "text_list = [\"十三年，署武昌知府。吴三桂犯湖南，师方攻岳州，檄成龙造浮桥济师，甫成，山水发，桥圮，坐夺官。\"]\n",
    "results = generate_output_from_text_batch(text_list)\n",
    "print(f\"results={results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进行评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义全局常量\n",
    "# eva_file_path=用于评估的文件路径\n",
    "# output_file_path=评估结果输出路径\n",
    "\n",
    "eva_file_path = r\"../data/version4/sampled_1000_merged_output_20230812_190843.json\"\n",
    "output_file_path = \"./data/eval_results/\"\n",
    "\n",
    "# 检查输出文件夹是否存在，如果不存在则创建\n",
    "if not os.path.exists(output_file_path):\n",
    "    os.makedirs(output_file_path)\n",
    "\n",
    "# 读取评估数据\n",
    "with open(eva_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu(reference, candidate):\n",
    "    reference = [list(reference)]\n",
    "    candidate = list(candidate)\n",
    "    return sentence_bleu(reference, candidate, smoothing_function=SmoothingFunction().method1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seconds_to_hms(seconds):\n",
    "    \"\"\"将秒数转换为小时、分钟和秒的格式。\"\"\"\n",
    "    parts = []\n",
    "    hours = seconds // 3600\n",
    "    if hours > 0:\n",
    "        parts.append(f\"{int(hours)}小时\")\n",
    "    minutes = (seconds % 3600) // 60\n",
    "    if minutes > 0:\n",
    "        parts.append(f\"{int(minutes)}分钟\")\n",
    "    seconds = seconds % 60\n",
    "    if seconds > 0 or len(parts) == 0:\n",
    "        parts.append(f\"{int(seconds)}秒\")\n",
    "    return ''.join(parts)\n",
    "\n",
    "def evaluate_in_batches(data, batch_size, evaluation_results):\n",
    "    total_samples = len(data)\n",
    "    total_bleu_score = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"开始评估，共 {total_samples} 个样本.\")\n",
    "\n",
    "    for i in tqdm(range(0, total_samples, batch_size), desc=\"评估进度\"):\n",
    "        # 切分批量数据\n",
    "        batch_data = data[i:i + batch_size]\n",
    "        batch_inputs = [example[\"input\"] for example in batch_data]\n",
    "        batch_truths = [[example[\"output\"]] for example in batch_data]\n",
    "        batch_results = generate_output_from_text_batch(batch_inputs)\n",
    "\n",
    "        for j, result_str in enumerate(batch_results):\n",
    "            # 如果有多个参考答案，选择BLEU分数最高的一个\n",
    "            max_bleu_score = max(calculate_bleu(truth, result_str) for truth in batch_truths[j])\n",
    "            total_bleu_score += max_bleu_score\n",
    "\n",
    "            # 将每个样本的评估结果添加到evaluation_results中\n",
    "            evaluation_results[\"samples\"].append({\n",
    "                \"inputs\": batch_inputs[j],\n",
    "                \"truth\": batch_truths[j][0],\n",
    "                \"results\": result_str,\n",
    "                \"BLEU\": max_bleu_score\n",
    "            })\n",
    "\n",
    "    # 计算平均BLEU分数和总评估时长\n",
    "    average_bleu_score = total_bleu_score / total_samples\n",
    "    total_time = time.time() - start_time\n",
    "    evaluation_results[\"scores\"][\"average_BLEU\"] = average_bleu_score\n",
    "    evaluation_results[\"infos\"][\"evaluation_duration\"] = seconds_to_hms(total_time)\n",
    "    print(f\"\\nBatch={batch_size}\")\n",
    "    print(f\"\\n评估完成，平均BLEU分数为: {average_bleu_score:.3f}, 总耗时: {seconds_to_hms(total_time)}\")\n",
    "    return evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始评估，共 1000 个样本.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度: 100%|██████████| 1000/1000 [16:19<00:00,  1.02it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch=1\n",
      "\n",
      "评估完成，平均BLEU分数为: 0.175, 总耗时: 16分钟19秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 设置批大小\n",
    "batch_size = 1  # 根据需要调整批大小\n",
    "total_samples = len(data)\n",
    "\n",
    "# 初始化评估结果字典\n",
    "evaluation_results = {\n",
    "    \"scores\": {\"average_BLEU\": 0},\n",
    "    \"infos\": {\n",
    "        \"evaluation_time\": time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime()),\n",
    "        \"model_name_or_path\": \"model_name\",\n",
    "        \"eva_file_path\": \"evaluation_file_path\",\n",
    "        \"total_samples\": total_samples\n",
    "    },\n",
    "    \"samples\": []\n",
    "}\n",
    "\n",
    "# 进行评估\n",
    "evaluation_results = evaluate_in_batches(data, batch_size, evaluation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "评估完成，平均BLEU分数为: 0.18\n",
      "评估结果已保存到 ./data/eval_results/eval_resu_20231224170900.json\n"
     ]
    }
   ],
   "source": [
    "result_file = os.path.join(output_file_path, f\"eval_resu_{time.strftime('%Y%m%d%H%M%S', time.localtime())}.json\")\n",
    "with open(result_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(evaluation_results, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"评估完成，平均BLEU分数为: {evaluation_results['scores']['average_BLEU']:.2f}\")\n",
    "print(f\"评估结果已保存到 {result_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
